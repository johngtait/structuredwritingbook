<?xml version="1.0"?>
<db:chapter xmlns:db="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:strings="http://exslt.org/strings" version="5.0" xml:id="chapter.extract">
<db:title>Extract</db:title>


<db:para>A great deal of the content we produce, particularly technical and business content, is essentially a report in human language on the specific features of a product, process, or data set. If those features are described in any kind of formal data set, such as a database or software source code, we can use structured writing techniques to extract information from those sources to create and/or validate content.</db:para>
<db:section>
<db:title>Tapping external sources of content</db:title>
<db:para>We have talked throughout this book about moving content from the media domain to the document domain and from the document domain to the subject domain. We have seen the advantages that come from creating content in the subject domain, and we have looked at the processing algorithms that can use subject domain content to produce various kinds of publications in different media.</db:para>
<db:para>Subject domain content is simply content that is created and annotated in structures that are based on the subject matter rather than on the structure of documents or media. Subject domain structures tell you what the content is about, rather than how it should be published. You can therefore write algorithms that processes it based on what it is about rather than how it is presented.</db:para>
<db:para>Any data source that is contained and annotated in subject domain structures is therefor a source of subject domain content, whether it was intended to produce content from or not. This includes virtually all databases and quite a bit of software code. It also includes all authored content anywhere available (under an appropriate license) that contains any usable subject domain structures or annotations. All of this is potential material for generating content as part of your overall publishing process. As such, the extract algorithm can work effectively with many other structured writing algorithms.</db:para>
<db:para>Perhaps most obviously, extract and merge works with the composition algorithm. Extract  provides new sources of content for the composition algorithm to work with.</db:para>
<db:para>As a source of subject domain content, the extract algorithm also naturally separates content from formatting and contributes to the differential single sourcing algorithm.</db:para>
<db:para>By tapping existing information to build content, the extract algorithm also works hand in hand with the content reuse algorithm. In fact, it is really the highest expression of reuse, since it not only reuses content in the content system, but information from the organization at large, or even beyond the organization -- a process that further reduces duplication within the organization.</db:para>
<db:para>Because the extract and merge algorithm taps directly into external sources of information, it is also a great source of information for the conformance algorithm. At one level, it provides a canonical source of information to validate existing content against. At another level, it factors out part of the conformance problem from the authoring function.</db:para>
<db:para>If the authoring function is required to conform to information in these sources, the best way to do this is to generate content directly from these sources. Then responsibility for the correctness of the content is shifted to the people who maintain the source you are extracting form. Since they were already responsible for the correctness of the information, this does not create any additional work for them, which means that there is a significant net gain in efficiency for the organization.</db:para>
</db:section>
<db:section>
<db:title>Information created for other purposes</db:title>
<db:para>There is nothing new, of course, about generating content from database records. Database reporting is a highly important and sophisticated field in its own right and it would be entirely correct to characterize it as a type of structured writing. What sets it apart, largely, from other structured writing practices, is that the databases it reports on serves other business purposes besides being sources of content. An insurance company policy database, for instance, may be used to publish custom benefit booklets for plan participants but it is also used for processing claims. The design of the structures and data entry interfaces of these systems has tended to fall outside the realm (and the notice) of writers and authoring system designers.</db:para>
<db:para>This is a pity, because it has often resulted in organizations developing separate processes, tools, and repositories for content creation in which the information already contained in databases is researched, validated, recorded, and managed entirely independently on the content side of the house. Rather than treating code and databases as sources of content, writers treat them as research sources. They look information up in these sources and then go away and write content (in a separate repository) to relate the information from those sources.</db:para>
<db:para>The essence of the problem is that many content organizations choose to work in the media domain or the document domain and have neither the tools not the expertize to bridge the gap to all this material already available in the subject domain. But even when content organizations do extend their efforts into the subject domain, they are often blind to the fact that the subject domain content they are proposing to create already exists in the systems of another department.</db:para>
<db:para>Another way in which this is a pity is that when content is produced from these existing systems, for instance by a database reporting process, it exists in isolation from the rest of the content produced by the organization. Such content can often be quite sophisticated and beautifully formatted and published. But it is the product of an entire structured publishing chain that has to be separately developed and maintained.</db:para>
<db:para>In the field of software documentation we see the same pattern in regard to programming language API documentation. Much of the material of an API reference guide is a description of each function, what information is required as input (its parameters or arguments), the information it produces as output, and the errors or exceptions that it can generate. All of this information already exists in the code that implements the function.</db:para>
<db:para>API documentation tools such as JavaDoc or Sphinx extract this information from code and comments and turn it into publishable content. This is an application of subject-domain structured writing and the API documentation tools that do this implement an entire structured publishing system internally, producing final output, often in multiple formats.</db:para>
<db:para>And here we see all the same problems again:</db:para>
<db:itemizedlist>
<db:listitem>
<db:para>An entire publishing chain is maintained separately from the main content publishing chain.</db:para>
</db:listitem>
<db:listitem>
<db:para>The content produced from this publishing chain is isolated from all the other content produced by the organization.</db:para>
</db:listitem>
<db:listitem>
<db:para>Much of the same information is often created and maintained separately in a different repository and tool chain in the form programming guides and/or knowledge base articles.</db:para>
</db:listitem>
</db:itemizedlist>
<db:para>There are other cases of entirely separate publishing chains producing information that is isolated from the rest of an organization’s content. Technical support organizations create knowledge bases to answer commonly asked questions. The material in these knowledge bases is technical communication, plain an simple, yet it usually exists in isolation from the product documentation set, even to the extent that uses may not be able to search both the documentation and the knowledge base from the same search box. Most users, however, have no way of guessing whether the answer they are looking for is going to be in the docs or the knowledge base (or in the users forum, often yet another independent publishing system.)</db:para>
<db:para>There are a couple of ways to address these redundancies and the isolation that goes with them. One is to attempt to unify all content authoring and production in a single enterprise-wide system, often with a single set of content structures intended for use across all enterprise departments. However, this is a highly expensive and disruptive approach and tends to create interfaces and structures that are less usable and less specific to various business functions than the ones they replace. It also ignores the fact that many of the systems from which we wish to extract content exist for other purposes besides the content that is generated from them. Their subject-domain structures are specific and necessary to the database functions or software code generation they were built for.</db:para>
<db:para>Another approach is to leave the subject domain systems in place (and perhaps create more of them) and feed their output into a common document-domain publishing tool chain. It is a normal part of the publishing algorithm for subject-domain content to pass through the document domain on its way to media-domain publication. Subject domain content, by its nature, is not strongly tied to a particular document domain structure, so integrating many sources of subject domain content into a single publishing chain is not particularly onerous. (Specific management domain features of certain tool chains make things more complicated, but since the subject domain tends to factor out a lot of the management domain, this is not an insurmountable problem.)</db:para>
<db:para>Most enterprise-wide content systems are based on document-domain languages. (There is, after all, no way to create a single enterprise-wide subject-domain system, since an enterprise creates content on many subjects.) In principle, a document-domain system should be capable of integrating content from domain-specific subject-domain systems.  Unfortunately, it is not common for either the subject domain systems or the enterprise content systems to be designed with this kind of integration in mind.</db:para>
<db:para>Because of this, we sometimes have to find ways to extract content from these sources and feed them into a unified publishing chain. This creates the need for extraction algorithm (which are part of the synthesis algorithm within the overall publishing algorithm).</db:para>
</db:section>
<db:section>
<db:title>The Extraction Algorithm</db:title>
<db:para>A common example of the extraction algorithm is found in API documentation tools such as JavaDoc. These tools parse application source code to pull out things like the names of functions, parameters, and return values, which it then uses to create the outline, at least, of reference documentation. Essentially, it generates a human language translation of what the computer language code is saying.</db:para>
<db:para>How the extraction algorithm works depends entirely on how the source data is structured, but it should usually create output in the subject domain that clearly labels the pieces of information it has culled from the source. For instance, a Java function definition is a piece of structured content in which the role and meaning of each element is known from the pattern and syntax of the Java language itself (its grammar):</db:para>
<db:programlisting language="java">
boolean isValidMove(int theFromFile, 
                    int theFromRank, 
                    int theToFile, 
                    int theToRank) {
        // ...body
    }
</db:programlisting>
<db:para>This same information can be extracted by an algorithm that knows the grammar of Java to produce something that looks more like subject domain content:</db:para>
<db:programlisting language="sam">
java-function:
    name: isValidMove
    return-type: boolean
    parameters:: type, name
        int, theFromFile
        int, theFromRank
        int, theToFile
        int, theToRank
</db:programlisting>
<db:para>This is the same information, but in a different structure. In this structure, however, it is easily accessible by content processes and can then be processed through the rest of the publishing tool chain just like any other content.</db:para>
<db:para>Any structured data source that expresses the semantics of its data in a consistent way is a source of subject domain content. We just need to find a way to get at it.</db:para>
</db:section>
<db:section>
<db:title>The diversity of sources</db:title>
<db:para>When it comes to drawing content from diverse sources, the term single sourcing can mislead us. Single source can lead us to think that it means all source content is kept in a single place. Some vendors of content management systems would like to encourage this interpretation. But a better definition is that each piece of information comes from a single source. That is to say, that each piece of information comes from only one source, but there may be many sources, each maintaining different information (this is an aspect of the single source of truth algorithm).</db:para>
<db:para>This has nothing to do with keeping it all in the same place. Nor is keeping all content in the same place a particularly useful approach to ensuring that it is only stored once. Ensuring that content is only stored once, a process formally called “normalization” is actually about making sure that information, and the repository in which it is stored, meets an appropriate set of constraints.</db:para>
<db:para>This is not to say that there are never trivial differences between the ways in which different bodies within an organization store and manage information that should not be rationalized. There are all kind of isolated and ad hoc information stores in most organizations that could potentially be much more efficient and (vitally) much more accessible, with a degree of rationalization and centralization. But it does not follow at all that absolute centralization into a single system or a single data model is appropriate, useful, or even possible.</db:para>
<db:para>The best way to ensure that information is stored once is to have it stored in a system with the right constraints and the right processes for the people who create and manage that information. This may mean that an integrated publishing system will draw from diverse sources of information and content. The ability to extract content from these sources and to merge it with other content for publication is therefore central to an effective strategy.</db:para>
</db:section>
</db:chapter>
