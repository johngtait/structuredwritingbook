<?xml version="1.0" encoding="UTF-8"?>
<chapter>
<title>Auditing</title>
<annotations>
<p>Concepts</p>
<p><phrase><annotation type="concept">subject domain</annotation></phrase> <phrase><annotation type="concept">media domain</annotation></phrase> <phrase><annotation type="concept">document domain</annotation></phrase> <phrase><annotation type="concept">management domain</annotation></phrase> <phrase><annotation type="concept">subject-domain</annotation></phrase> <phrase><annotation type="concept">media-domain</annotation></phrase> <phrase><annotation type="concept">document-domain</annotation></phrase> <phrase><annotation type="concept">management-domain</annotation></phrase> <phrase><annotation type="concept">hybrid tagging language</annotation></phrase> <phrase><annotation type="concept">Every Page is Page One</annotation></phrase> <phrase><annotation type="concept">abstract language</annotation></phrase> <phrase><annotation type="concept">information architecture</annotation></phrase> <phrase><annotation type="concept" specifically="top-down information architecture">top-down</annotation></phrase> <phrase><annotation type="concept">metadata</annotation></phrase></p>
<p>Languages</p>
<p><phrase><annotation type="language">SAM</annotation></phrase> <phrase><annotation type="language">DITA</annotation></phrase> <phrase><annotation type="language">DocBook</annotation></phrase> <phrase><annotation type="language">Markdown</annotation></phrase> <phrase><annotation type="language">HTML</annotation></phrase> <phrase><annotation type="language">XML</annotation></phrase></p>
<p>Algorithms</p>
<p><phrase><annotation type="algorithm">authoring algorithm</annotation></phrase> <phrase><annotation type="algorithm">authoring</annotation></phrase> <phrase><annotation type="algorithm" specifically="composition">composability</annotation></phrase> <phrase><annotation type="algorithm">composition algorithm</annotation></phrase> <phrase><annotation type="algorithm">composition</annotation></phrase> <phrase><annotation type="algorithm">conformance algorithm</annotation></phrase> <phrase><annotation type="algorithm">conformance</annotation></phrase> <phrase><annotation type="algorithm">content management algorithm</annotation></phrase> <phrase><annotation type="algorithm">content management</annotation></phrase> <phrase><annotation type="algorithm">content reuse algorithm</annotation></phrase> <phrase><annotation type="algorithm">content reuse</annotation></phrase> <phrase><annotation type="algorithm">differential single sourcing algorithm</annotation></phrase> <phrase><annotation type="algorithm">differential single sourcing</annotation></phrase> <phrase><annotation type="algorithm">encoding algorithm</annotation></phrase> <phrase><annotation type="algorithm">encoding</annotation></phrase> <phrase><annotation type="algorithm">exchange algorithm</annotation></phrase> <phrase><annotation type="algorithm">exchange</annotation></phrase> <phrase><annotation type="algorithm">extract and merge algorithm</annotation></phrase> <phrase><annotation type="algorithm">extract and merge</annotation></phrase> <phrase><annotation type="algorithm">formatting algorithm</annotation></phrase> <phrase><annotation type="algorithm">formatting</annotation></phrase> <phrase><annotation type="algorithm">linking algorithm</annotation></phrase> <phrase><annotation type="algorithm">linking</annotation></phrase> <phrase><annotation type="algorithm">presentation algorithm</annotation></phrase> <phrase><annotation type="algorithm">presentation</annotation></phrase> <phrase><annotation type="algorithm">publishing algorithm</annotation></phrase> <phrase><annotation type="algorithm">publishing</annotation></phrase> <phrase><annotation type="algorithm">quality algorithm</annotation></phrase> <phrase><annotation type="algorithm">quality</annotation></phrase> <phrase><annotation type="algorithm">relevance algorithm</annotation></phrase> <phrase><annotation type="algorithm">relevance</annotation></phrase> <phrase><annotation type="algorithm">rendering algorithm</annotation></phrase> <phrase><annotation type="algorithm">rendering</annotation></phrase> <phrase><annotation type="algorithm">reuse algorithm</annotation></phrase> <phrase><annotation type="algorithm">reuse</annotation></phrase> <phrase><annotation type="algorithm">separating content from formatting</annotation></phrase> <phrase><annotation type="algorithm">single source of truth algorithm</annotation></phrase> <phrase><annotation type="algorithm">single source of truth</annotation></phrase> <phrase><annotation type="algorithm">single sourcing algorithm</annotation></phrase> <phrase><annotation type="algorithm">single sourcing</annotation></phrase> <phrase><annotation type="algorithm">synthesis algorithm</annotation></phrase> <phrase><annotation type="algorithm">synthesis</annotation></phrase> <phrase><annotation type="algorithm" specifically="conformance">validation</annotation></phrase></p>
<p>Tools</p>
<p><phrase><annotation type="tool">content management system</annotation></phrase> <phrase><annotation type="tool">Content management systems</annotation></phrase></p>
<p>Roles</p>
<p><phrase><annotation type="role">information architect</annotation></phrase></p>
</annotations>
<p>If the <phrase><annotation type="algorithm">conformance algorithm</annotation></phrase> is about making sure that an individual item meets its constraints, the <phrase>audit algorithm</phrase> is about making sure that the content set as a whole meets its constraints.<citation type="idref" value="1"/></p>
<footnote id="1">
<p><phrase><annotation type="concept" specifically="content strategy">Content strategists</annotation></phrase> often use the term “content audit” to mean a current state analysis performed at the beginning of a website redevelopment project. A content strategy content audit is about cataloging, and possibly categorizing, the content you already have. I am using the word audit to refer to an ongoing and or recurring activity in which a you ensure that a content set is meeting or continuing to meet its goals.</p>
</footnote>
<p>As such, auditing is fundamentally a <phrase><annotation type="algorithm">content management</annotation></phrase> function. It is about making sure that:</p>
<ul>
<li>
<p>The definition of the content set is correct (we know what types of content it should contain, and which instances of each type)</p>
</li>
<li>
<p>The content set is complete (it contains all the items of each type that it should)</p>
</li>
<li>
<p>The content set is uncontaminated (it does not contain any items or types it should not)</p>
</li>
<li>
<p>The content set is integrated (it contains all of the relationships between items that it should)</p>
</li>
<li>
<p>Each item in the content set <phrase>conforms</phrase> to its constraints</p>
</li>
</ul>
<p>Auditing marketing content can be easier than auditing other types of content because you can measure content against behavioral goals. Are readers taking the actions you want, and does a content change produce more of the desired action? All content aims at changing reader behavior in one way or another, but not all behavior changes are easy to measure. Unless the behavior in question is an interaction with the web page that contains the content, behavioral changes are both hard to observe and hard to attribute. And even where behavior is measurable, you want to be able to reproduce the qualities of content that produce the behavior you want, and that means auditing the type and coverage of your content.</p>
<p>Auditing a large content set is difficult and many CMS solutions are deficient in audit capabilities. The main reason for this is that with the way most content is recorded and stored (<phrase><annotation type="concept">media domain</annotation></phrase> or generic <phrase><annotation type="concept">document domain</annotation></phrase> formats), it is very difficult to mechanically assess what content you have and what state it is in. It is hard to know if you have all the pieces you should have if you can’t tell exactly what the pieces you have are.</p>
<p>Auditing is a content management function and this book is about structured writing, not content management. However, one of the biggest, and least appreciated, benefits of structured writing is that it makes content more auditable. When content management systems fails or become unmanageable, (which they do with disappointing frequency), the root cause is often either lack of attention to regular audits, or the lack of ability to audit effectively. Without the ability to audit effectively, content sets often end up incomplete, corrupt, and poorly integrated, which reduced quality and increases costs at every stage of the process. And a viscous cycle can develop in which writers, frustrated with the difficulties of the system, create workarounds that further corrupt the information set.  Whatever expenses you may incur to implement a more structured structured writing approach could well be offset by the savings associated with more effective auditing of the content set alone.</p>
<section>
<title>Correctness of the definition of the content set</title>
<p><phrase><annotation type="concept" specifically="content strategy">Content strategists</annotation></phrase> will spend a great deal of time and effort developing a content plan (usually this is for a website, but the same principle applies to any content set). How they do this is beyond the scope of this book, but the result should be a definition of the content set: which types of information it is supposed to contain and what instances of those types. (This definition is based, of course on the goals it is designed to achieve, which is the business of the content strategist to define.)</p>
<p>The definition of a content set is not necessarily static. It is not necessarily a fixed list of topic types or of specific topics to be developed. For one thing, the subject matter may change during the course of content development, which would change the content pieces needed, and perhaps require new content types or modifications to existing types. Second, the exact set of pieces or types may not be knowable at the outset. Content development explores a complex set of relationships between subject matter and the needs and background of the reader that cannot be fully known without traveling the ground in detail. An agile approach to content planning is essential in most content projects. But remember that agile is a disciplined approach to evolving a plan. It does not mean hacking away regardless; it means constantly refining your model in a disciplined and deliberate way as you learn more about you subject matter, your readers, and your business needs.</p>
<p>But is is hard to be disciplined and deliberate in evolving the big picture model of the content set if you are not disciplined and deliberate in how you create the pieces. If the author is given no guidance and is then asked to assign CMS metadata to the article after the fact, they will tag it using the terms that seems like the closest fit, but they will not revise the content to fit the labels they are applying to it. You won’t really know what type of content you have.</p>
<p>If you don’t really know what type of content you have, you can’t really tell if the definitions for your content are correct. Some content may perform poorly because it does not fit the type definition properly. But you can’t tell whether it failed because it didn’t fit the type definition or because the type definition is wrong. Thus you don’t know what to fix.</p>
<p>Similarly, an author may write something that is better than the current type definition. But if it is tagged as that type in the CMS, the type definition will get the credit for the success. But then the problem is that you don’t detect the problem with the type definition, and so you don’t change it. But then the content of other authors who follow the type definition does not work as well, giving you inconsistent results that are hard to interpret. Unless your content types are codified and auditable, their success won’t carry over to other content. And if the content fails, you won’t know whether it failed because it was true to a badly defined type or false to a well defined one.</p>
<p>Having strong well defined topic types makes it easier to audit your topic types to make sure they are doing the job they were designed to do. Similarly, having strong well defined topic types means that you can have greater assurance that each topic is doing the job it is supposed to do, which helps you make sure you have covered all the subjects you should have.</p>
<p>But structured writing can do more than this to help you audit the definition of the content set. If create content in the subject domain, including extensively annotating the subjects that you mention in the text, you can use algorithms to extract a list of the types and subjects that your content is actually talking about. In your initial top-down plan, you many not have thought about the need for content on a certain subject or to support a certain activity, but if that subject or that activity start showing up in the body of your content, that is a strong indication that those subjects and activities are related to the purpose of your content set and should probably be included in the definition of the content set.</p>
<p>Subject domain markup is how you know what your content is actually talking about, what every author is discovering or thinks needs saying. Without this information it is very difficult to audit that the content set is meeting its coverage goals.</p>
<p>This actually attacks two audit problems. If writers are writing about things outside you current coverage definition, either your coverage definition needs updating, or writers are polluting the content set with irrelevant material.</p>
</section>
<section>
<title>Ensuring the content set remains uncontaminated</title>
<p><phrase>Subject domain</phrase> content structures and annotations can help you prevent contamination of the content set by irrelevant material. But more important than catching writers in the act is catching the flaws in content types that allow for contamination to creep in.</p>
<p>A major form of contamination in any content set is redundant content. We have to be careful in how we define redundancy, because it is not simply a matter of only addressing a subject once, it is a matter of addressing an audience need only once, and that may require several topics on the same subject addressed to different readers. But it is all too easy for duplicate content to sneak into a content set. Some of it comes in because the same functionality is repeated in many products or in content delivered to different media. Some comes in through authors simply not knowing that suitable content already exists. <phrase>Content reuse</phrase> is a major motivator for structured writing for exactly this reason. But the <phrase><annotation type="algorithm">content reuse</annotation></phrase> algorithm only addresses the problem of how to reuse content. It provides a method to reuse content you are aware of. It does not prevent you from duplicating content because you did not look for or did not find existing reusable content.</p>
<p>There are natural language processing algorithms that will attempt to identify redundant content in a content set, but such algorithms focus on similar texts. This is not enough. The same or similar sequences of words may occur in different places without being redundant. They may mean different things, or perform different roles, in context. On the other hand, redundant pieces of information may be expressed in very different words. In other words, it is redundant information, not redundant phrases, the we care about.</p>
<p>Even when redundancies are found, they may be very difficult to consolidate if they don’t have similar boundaries within their respective documents (the <phrase><annotation type="algorithm" specifically="composition">composability</annotation></phrase> problem) (see <citation type="nameref" value="chapter.composition"/>). Strongly typed content, meaning content that conforms to a model that breaks down and enforces the various components that make up a document, makes it possible to detect duplication in a much more formal and precise way.</p>
<p>A person who consults a repository to see if there is a piece of content they can use relies on the ability to query the repository in a sensible way for the type of content they are looking for. They also rely on their ability to recognize the content when they see it, and on it actually being strongly conformant so that they can use it with confidence. Strong topic typing helps with all of these things. The easier it is to correctly identify reusable content and use it, the less corruption of the repository will occur.</p>
</section>
<section>
<title>Ensuring that the content set is well integrated</title>
<p>A content set is never a collection of wholly independent pieces. The items in the set have relationships to each other that matter to the reader. Whether you express those relationships on output through links or cross references, or whether you relay entirely on tables on contents and indexes, it is still important to understand and manage the relationships between items.</p>
<p>Relationships between items may also be things that matter for management but not to readers. If your have documentation for multiple releases of a product, the relationship between the documentation for for feature X in version 3 and that for feature X in version 2 matters to you. It may matter because the feature has not changed and you can reuse the item. It may matter because an error was found in version 2 and you want to fix it in version 3 as well. And if you put this content online, the relationship may matter for the reader as well, if they search for feature X and get the result for version 2 when they are using version 3.</p>
<p>You can describe the relationship between items externally. Items are related whenever they share any part of a metadata record in common. But the same problem exists here as it always does with external metadata (see <citation type="nameref" value="chapter.content-management"/>)-- the content may not conform to the metadata, and without structured writing in the content itself, it is hard to audit the conformance of the content to its metadata. But the bigger problem is that in may cases the important relationship are between parts of one item and the wholes of others. Are function names appearing in the programming topics all listed in the API reference? Are the utensils mentions in a recipe all covered in the appendix of kitchen tools?</p>
<p>Structured writing, particularly in the subject domain, helps you discover and manage these relationships by making clear the subject on which these relationships are based.</p>
</section>
<section>
<title>Making content auditable</title>
<p>I have talked all through this chapter about how using strong topic types makes content easier to audit. What is a strong topic type? Fundamentally, a strong topic type is one that makes explicit what the content is supposed to say an how it is supposed to say it. Or, to put it another way, a strong topic type is one that captures, enforces, or factors out the major constraints of the content, including its major rhetorical constraints.</p>
<p>It is possible for content to conform to all of its rhetorical constraints without the use of structured writing techniques. But strong topics types provide explicit guidance to the author and facilitate the use of <phrase><annotation type="algorithm">conformance</annotation></phrase> algorithms. They are created to meet your conformance goals. Similarly with auditing, you specify the content structures you need in order to meet your auditing goals.</p>
<p>Auditing is sometimes not as straightforward as conformance, even with structured writing techniques in place. Auditing often requires human review, not only to make sure that all subjects have been covered, but to discover new issues or subjects that need to be addressed. Human review of a large content set is difficult, though, due to the sheer amount of content. An <phrase>audit algorithm</phrase> can simplify this work by creating different views of the content set that humans can review more easily.</p>
<p>Suppose, for instance, that an organization is using subject-domain annotations to drive linking. Every topic in the collection is supposed to be indexed to state the type and names of the subjects it covers. Every mention of a significant subject is supposed be annotated with its type. The <phrase><annotation type="algorithm">linking algorithm</annotation></phrase> can certainly use these annotations and index entries to link the content without any need for authors to create or manage links in the source text (as described in <citation type="nameref" value="chapter.linking"/>. But that does not guarantee that all the right links get made. There could be errors in indexing or annotation that are impossible to detect when <phrase><annotation type="algorithm">conformance</annotation></phrase> testing individual topics.</p>
<p>We can use those same index entries and annotations to create audit reports for several purposes. These are some of the things we can do:</p>
<ul>
<li>
<p>We can create a sorted list of all the phrases that have been annotated and see if they are being annotated consistently. (Everyone is using the same annotation type, for instance.) This will tell us a lot about the types we are using, how well they are understood, and what instances of each type we should be covered.</p>
</li>
<li>
<p>We can create a list of all the phrases that have been indexed and check it against our content plan (perhaps against a taxonomy if we have one). This will tell us a lot about if our coverage is complete, if writers are getting off track, or if our content plan or our taxonomy is off base with reality.</p>
</li>
<li>
<p>We can create a sorted list of all the index terms and check it against the list of annotated phrases to find phrases are that being indexed but not annotated or annotated but not indexed. This can tell us is there are subject we are not covering, if writers are discussing subjects they should not be, or if some topics are not being indexed or annotated properly.</p>
</li>
<li>
<p>During the content development phase, the list of things that are annotated but not indexed will inevitable grow, as subjects are being referred to before the content that describes them is written. The trend line of the growth of new subjects being annotated vs subjects being indexed will allow you to track how close a content set is to completion, even in cases were defining the boundaries in a advance is difficult.</p>
<!--  FIXME: Needs an example audit report. Generate one for the book to illustrate the idea. -->
</li>
</ul>
</section>
</chapter>
